{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualiztion\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# raw data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# for linear regression models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms \n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "\n",
    "# recursive feature elimination (w/ cross validation), linear regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Variance inflation factor, mean abs/squarred error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings # weird sns.distplot() warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# make stuff look cooler\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates dictionary of variance inflation factors. \n",
    "def create_vif_list(X):\n",
    "    X = sm.add_constant(X)\n",
    "    vif_dict = {}\n",
    "\n",
    "    for i in range(len(X.columns)):\n",
    "        vif = variance_inflation_factor(X.values, i)\n",
    "        v = X.columns[i]\n",
    "        vif_dict[v] = vif\n",
    "\n",
    "    good_vifs = []\n",
    "    bad_vifs = []\n",
    "\n",
    "    for k,v in vif_dict.items():\n",
    "        if v < 10:\n",
    "            good_vifs.append(k)\n",
    "        else:\n",
    "            bad_vifs.append(k)\n",
    "\n",
    "    return good_vifs,bad_vifs\n",
    "\n",
    "def create_vif_dictionary(X):\n",
    "    X = sm.add_constant(X)\n",
    "    vif_dict = {}\n",
    "\n",
    "    for i in range(len(X.columns)):\n",
    "        vif = variance_inflation_factor(X.values, i)\n",
    "        v = X.columns[i]\n",
    "        vif_dict[v] = vif\n",
    "\n",
    "    return vif_dict\n",
    "\n",
    "# create a dictionary showing the adjusted R-squared values for each feature individually\n",
    "def create_R2_dictionary(X,y):\n",
    "\n",
    "    adj_R_squares = {}\n",
    "\n",
    "    for feature in X.columns:\n",
    "        predictors_int = sm.add_constant(X[feature])\n",
    "        model = sm.OLS(y,predictors_int).fit()\n",
    "        adj_R_square = float(model.summary2().tables[0][3][0])\n",
    "        adj_R_squares[feature] = adj_R_square\n",
    "        \n",
    "    return adj_R_squares\n",
    "\n",
    "# author's docstring is in a markup cell down below in the stepwise selection section\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            worst_feature_name = included[worst_feature]\n",
    "            included.pop(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature_name, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# recursive feature elimination\n",
    "def run_RFE(X,y):\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "    selector = RFE(linreg)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    selected = selector.support_ # list of bools representing if feature is selected or not\n",
    "    selections = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(selected): # append labels of selected features to selections list\n",
    "        if feature == True:\n",
    "            selections.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ranked = selector.ranking_ # list of bools representing if feature is selected or not\n",
    "    rankers = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(ranked): # append labels of selected features to selections list\n",
    "        if feature == 1:\n",
    "            rankers.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    return selections, rankers\n",
    "\n",
    "# recuersive feature elimination with cross validation\n",
    "def run_RFECV(X,y,select_rank=False):\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "    selector = RFECV(linreg)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    selected = selector.support_ # list of bools representing if feature is selected or not\n",
    "    selections = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(selected): # append labels of selected features to selections list\n",
    "        if feature == True:\n",
    "            selections.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ranked = selector.ranking_ # list of bools representing if feature is selected or not\n",
    "    rankers = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(ranked): # append labels of selected features to selections list\n",
    "        if feature == 1:\n",
    "            rankers.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if select_rank == True:\n",
    "        return selections\n",
    "    else:\n",
    "        return rankers\n",
    "\n",
    "# returns OLS linear regression model\n",
    "def run_OLS_model(X,y):\n",
    "\n",
    "    predictors_int = sm.add_constant(X)\n",
    "    model = sm.OLS(y,predictors_int).fit()\n",
    "\n",
    "    return model\n",
    "\n",
    "# returns dictionary: keys are column labels, values are count of NaN values present\n",
    "def create_NaN_dictionary(X):\n",
    "\n",
    "    NaN_dict = {}\n",
    "\n",
    "    for feature in X.columns:\n",
    "        NaN_dict[feature] = sum(X[feature].isna())\n",
    "\n",
    "    return NaN_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up dataframe and deal with some missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/kc_house_data.csv')\n",
    "X.drop(X.loc[X['sqft_basement']=='?'].index,inplace=True) # remove '?' from the data.\n",
    "X.drop(['id','lat','long'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate target variable outliers\n",
    "(for price column, drop anything more than 3 standard deviations from the mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_thresh = X.price.std()*3 # three standard deviations\n",
    "X = X.loc[abs(X['price']) <= std_thresh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpret tax bracket by zipcode according to average income from IRS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('data/irs_income_by_zipcode.csv')\n",
    "\n",
    "income.avg_taxable_income = income.avg_taxable_income*1000 # scaling data back to dollar units (was in thousands)\n",
    "income.taxable_income_amount = income.taxable_income_amount*1000 \n",
    "income.rename({'taxable_income_amount':'zip_tax_revenue'},axis=1,inplace=True) # renaming to something more idiomatic\n",
    "\n",
    "# # create lists to stage data in order to concat new columns later\n",
    "single_filing_bracket = [] # for the single filing tax schedule\n",
    "joint_filing_bracket = [] #for the joint filing tax schedule\n",
    "\n",
    "# assign tax bracket based on average income\n",
    "for average in income.avg_taxable_income:\n",
    "    if average > 523600:\n",
    "        single_filing_bracket.append(7)\n",
    "    elif average <= 9950:\n",
    "        single_filing_bracket.append(1)\n",
    "    elif (average >= 9951) and (average <= 40525):\n",
    "        single_filing_bracket.append(2)\n",
    "    elif (average >= 40526) and (average <= 86375):\n",
    "        single_filing_bracket.append(3)\n",
    "    elif (average >= 86376) and (average <= 164924):\n",
    "        single_filing_bracket.append(4)\n",
    "    elif (average >= 164925) and (average <= 209425):\n",
    "        single_filing_bracket.append(5)\n",
    "    elif (average >= 209426) and (average <= 523600):\n",
    "        single_filing_bracket.append(6)\n",
    "\n",
    "for average in income.avg_taxable_income:\n",
    "    if average > 628301:\n",
    "        joint_filing_bracket.append(7)\n",
    "    elif average <= 19900:\n",
    "        joint_filing_bracket.append(1)\n",
    "    elif (average >= 19901) and (average <= 81050):\n",
    "        joint_filing_bracket.append(2)\n",
    "    elif (average >= 81051) and (average <= 172750):\n",
    "        joint_filing_bracket.append(3)\n",
    "    elif (average >= 172751) and (average <= 329850):\n",
    "        joint_filing_bracket.append(4)\n",
    "    elif (average >= 329851) and (average <= 418850):\n",
    "        joint_filing_bracket.append(5)\n",
    "    elif (average >= 418851) and (average <= 628300):\n",
    "        joint_filing_bracket.append(6)\n",
    "\n",
    "# assign discovered data to new column\n",
    "income['single_filing_tax_bracket'] = single_filing_bracket\n",
    "income['joint_filing_tax_bracket'] = joint_filing_bracket\n",
    "\n",
    "# create dictionary of zipcodes with corresponding tax bracket\n",
    "# dictionary will be used to assign create similar columns in the principal data.\n",
    "single_filing_tax_dict = {}\n",
    "joint_filing_tax_dict = {}\n",
    "\n",
    "# create ditionaries to later assign values to principal data\n",
    "for row in income.iterrows():\n",
    "    single_filing_tax_dict[row[1][0]] = row[1][3]\n",
    "    joint_filing_tax_dict[row[1][0]] = row[1][4]\n",
    "\n",
    "# concat columns to X containing tax bracket based on single and joint filing federal income tax schedule\n",
    "X['single_filing_bracket'] = X.zipcode.replace(to_replace=single_filing_tax_dict) # single filing \n",
    "X['joint_filing_bracket'] = X.zipcode.replace(to_replace=joint_filing_tax_dict) # joint filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert object type data into numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string types into np floats\n",
    "X.sqft_basement = [float(sq) for sq in list(X.sqft_basement)]\n",
    "\n",
    "# Replaces grade strings with numerics based on data dict. \n",
    "grade_raws = list(X.grade.unique())\n",
    "# replaces a cell value with the int of the first character of its existing string\n",
    "for raw in grade_raws:\n",
    "    X.grade.replace(to_replace=raw,value=int(raw[0]),inplace=True)\n",
    "\n",
    "# replaces condition objects with numerics based on data dict.\n",
    "condition_dict = {'Poor':1,'Fair':2,'Average':3,'Good':4,'Very Good':5}\n",
    "for key in condition_dict:\n",
    "    X.condition.replace(to_replace=condition_dict,inplace=True)\n",
    "\n",
    "# replace yr_built NaNs with numeric 0\n",
    "X.yr_renovated.replace(to_replace=np.nan,value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert waterfront into numeric boolean\n",
    "waterfront_bool_list = []\n",
    "\n",
    "for value in X.waterfront:\n",
    "    if value == 'YES':\n",
    "        waterfront_bool_list.append(1)\n",
    "    else:\n",
    "        waterfront_bool_list.append(0)\n",
    "        \n",
    "X.waterfront = waterfront_bool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert view from string into categorical ordinal\n",
    "view_rank_list = [] \n",
    "view_dict = {'NONE':0,'FAIR':1,'AVERAGE':2,'GOOD':3,'EXCELLENT':4}\n",
    "\n",
    "for value in X.view:\n",
    "    if value in list(view_dict.keys()):\n",
    "        view_rank_list.append(view_dict[value])\n",
    "    else:\n",
    "        view_rank_list.append(0)\n",
    "        \n",
    "X.view = view_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into ordinals \n",
    "X.date = pd.to_datetime(X['date'])\n",
    "X.date = X['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = create_NaN_dictionary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcitonize this ?? \n",
    "\n",
    "cor_df=X.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "cor_df['pairs'] = list(zip(cor_df.level_0, cor_df.level_1))\n",
    "cor_df.set_index(['pairs'], inplace = True)\n",
    "cor_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "cor_df.columns = ['cc']\n",
    "cor_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairs</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(single_filing_bracket, joint_filing_bracket)</th>\n",
       "      <td>0.869690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_living, sqft_above)</th>\n",
       "      <td>0.853341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_living15, sqft_living)</th>\n",
       "      <td>0.736795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_above, sqft_living15)</th>\n",
       "      <td>0.716207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_living, bathrooms)</th>\n",
       "      <td>0.716197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_lot, sqft_lot15)</th>\n",
       "      <td>0.707240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_above, bathrooms)</th>\n",
       "      <td>0.638031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sqft_living, price)</th>\n",
       "      <td>0.619520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     cc\n",
       "pairs                                                  \n",
       "(single_filing_bracket, joint_filing_bracket)  0.869690\n",
       "(sqft_living, sqft_above)                      0.853341\n",
       "(sqft_living15, sqft_living)                   0.736795\n",
       "(sqft_above, sqft_living15)                    0.716207\n",
       "(sqft_living, bathrooms)                       0.716197\n",
       "(sqft_lot, sqft_lot15)                         0.707240\n",
       "(sqft_above, bathrooms)                        0.638031\n",
       "(sqft_living, price)                           0.619520"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df[(cor_df.cc>.60) & (cor_df.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping joint_filing_bracket due to colinearity, will re-inspect the rest after one-hot encoding\n",
    "X.drop('joint_filing_bracket',axis=1,inplace=True)\n",
    "\n",
    "# renaming single_filing_bracket since it is now the only tax bracket feature and the name will be more idomatic\n",
    "X.rename({'single_filing_bracket':'average_tax_bracket'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering inferred features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ratios \n",
    "- bed bath ratio:           ratio of bedrooms to bathrooms\n",
    "- level ratios:             ratio of square feet above 'grade' and below (ratio of everything else to the basement)\n",
    "- live_lot_ratio:           ratio of living space to lot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbratios = []\n",
    "lvl_ratios = []\n",
    "live_lot_ratio = []\n",
    "\n",
    "for index,row in X.iterrows(): #iterate through every record\n",
    "\n",
    "    bbratio = row.bedrooms/row.bathrooms # calculate ratio of bedrooms to bathrooms\n",
    "    bbratios.append(bbratio) # append ratio to the list\n",
    "\n",
    "    LLratio = row.sqft_living/row.sqft_lot\n",
    "    live_lot_ratio.append(LLratio)\n",
    "\n",
    "    if row.sqft_basement == 0: # sqft_basement is zero if there is no basement\n",
    "        lvl_ratios.append(0) # ratio should also be zero if there is no ratio\n",
    "        \n",
    "    else:\n",
    "        lvl_ratio = row.sqft_above / row.sqft_basement # calculate ratio of space above grade vs below grade\n",
    "        lvl_ratios.append(lvl_ratio) # append ratio to the list\n",
    "\n",
    "X['bed_bath_ratio'] = bbratios # create new column and asign list as its values\n",
    "X['level_ratio'] = lvl_ratios # create new column and asign list as its values\n",
    "X['live_lot_ratio'] = live_lot_ratio # you get the idea . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### diferences \n",
    "- relative living space:    ratio of living space to the living space of the nearest 15 houses (sqft_living :: sqft_living15)\n",
    "- relatve lot size:         same as living space but for lot size instead. \n",
    "- level difference:         difference in square footage of living space to basement space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_live_space = []\n",
    "rel_lot_size = [] \n",
    "rel_difference = []\n",
    "\n",
    "for index,row in X.iterrows(): # for every record \n",
    "    live_dif = row.sqft_living - row.sqft_living15 # calculate difference in sqft of the given house and the nearest 15 other houses\n",
    "    rel_live_space.append(live_dif) # append it to the list\n",
    "\n",
    "    lot_dif = row.sqft_lot - row.sqft_lot15 # calculate difference in sqft of the given lot and the nearest 15 other lots\n",
    "    rel_lot_size.append(lot_dif) # append it to the list\n",
    "\n",
    "    lvl_dif = row.sqft_above - row.sqft_basement # calculate difference between space above grade and below grade\n",
    "    rel_difference.append(lvl_dif) # append it to the list\n",
    "\n",
    "X['relative_living_space'] = rel_live_space # assign respective list to new column \n",
    "X['relative_lot_size'] = rel_lot_size\n",
    "X['level_difference'] = rel_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and one-hot encode categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using zipcodes to discover proximal waterfronts and one-hot encoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_loc_dict = {'Duwamish':[98168],\n",
    "'Elliott Bay':[98119,98104,98129,98132,98127,98125,98195,98101,98134,98170,98139,98131,98181], \n",
    "'Puget Sound':[98071,98083,98013,98070,98031,98131,98063,98195,98207,98190], \n",
    "'Lake Union':[98109], \n",
    "'Ship Canal':[00000], \n",
    "'Lake Washington':[98072,98077], \n",
    "'Lake Sammamish':[98074,98075,98029], \n",
    "'other lake':[00000], \n",
    "'river/slough waterfronts':[00000]}\n",
    "\n",
    "# list to contain new column data\n",
    "waterfront_list = []\n",
    "\n",
    "# for loop to assign waterfront based on zipcode\n",
    "for zipcode in X.zipcode:\n",
    "    for k,v in water_loc_dict.items():\n",
    "        if zipcode in v:\n",
    "            waterfront_list.append(k)\n",
    "            appended = True\n",
    "            break\n",
    "        else: \n",
    "            appended = False\n",
    "    if not appended:\n",
    "        waterfront_list.append('NONE')\n",
    "\n",
    "# print(len(waterfront_list),set(waterfront_list))\n",
    "X['waterfront_loc'] = waterfront_list\n",
    "\n",
    "# create dummy variables\n",
    "waterfront_dummies = pd.get_dummies(X.waterfront_loc).drop('NONE',axis=1).add_prefix('waterfront_')\n",
    "\n",
    "# reasign X to concatenated dataframe, dropping features no longer needed\n",
    "X = X.drop(['waterfront_loc','zipcode'],axis=1)\n",
    "X = pd.concat([X,waterfront_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Data by tax bracket and separate target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brackets = X.set_index(['average_tax_bracket']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = brackets.price\n",
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect multicolinearity of features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on variance inflation factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'const': 42738836.58948342,\n",
       " 'date': 1.0080290934828011,\n",
       " 'price': 2.2060728862151415,\n",
       " 'bedrooms': 5.853952466616593,\n",
       " 'bathrooms': 10.84789886361396,\n",
       " 'sqft_living': inf,\n",
       " 'sqft_lot': inf,\n",
       " 'floors': 2.953092056279339,\n",
       " 'waterfront': 1.1067408069132714,\n",
       " 'view': 1.2103293132086186,\n",
       " 'condition': 1.2414048300946874,\n",
       " 'grade': 1.0981754823293823,\n",
       " 'sqft_above': inf,\n",
       " 'sqft_basement': inf,\n",
       " 'yr_built': 2.3238414790353206,\n",
       " 'yr_renovated': 1.1058092024836328,\n",
       " 'sqft_living15': inf,\n",
       " 'sqft_lot15': inf,\n",
       " 'bed_bath_ratio': 7.343750843333311,\n",
       " 'level_ratio': 1.1385391920633154,\n",
       " 'live_lot_ratio': 2.308020253032007,\n",
       " 'relative_living_space': inf,\n",
       " 'relative_lot_size': inf,\n",
       " 'level_difference': inf,\n",
       " 'waterfront_Duwamish': 1.032434705624118,\n",
       " 'waterfront_Elliott Bay': 1.0238292928846264,\n",
       " 'waterfront_Lake Sammamish': 1.12357619890305,\n",
       " 'waterfront_Lake Union': 1.0215981410019366,\n",
       " 'waterfront_Lake Washington': 1.0509886825433166,\n",
       " 'waterfront_Puget Sound': 1.0443308102758029}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good,bad = create_vif_list(brackets)\n",
    "vif_dict = create_vif_dictionary(brackets)\n",
    "vif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = brackets.drop(bad[1:],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on colinearity coefficient threshold of 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df=X.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "cor_df['pairs'] = list(zip(cor_df.level_0, cor_df.level_1))\n",
    "cor_df.set_index(['pairs'], inplace = True)\n",
    "cor_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "cor_df.columns = ['cc']\n",
    "cor_df.drop_duplicates(inplace=True)\n",
    "cor_df = cor_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pairs, cc]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df[(cor_df.cc>.60) & (cor_df.cc <1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Transformation and Feature ranking \n",
    "using standardization (x - x_bar / sigma) to normalize units of measurement\n",
    "\n",
    "investigate feature rankings using:\n",
    "- stepwise method\n",
    "- recursive elimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardized = pd.DataFrame([]) # data standardized\n",
    "\n",
    "for feature in X.columns:\n",
    "    x_comp = (X[feature] - np.mean(X[feature])/np.std(X[feature])) # (x - x_bar)/sigma\n",
    "    X_standardized[feature] = x_comp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline models for each tax bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dict = {\n",
    "'two':run_OLS_model(X.loc[2,:],y_log[2]), \n",
    "'three':run_OLS_model(X.loc[3,:],y_log[3]), \n",
    "'four':run_OLS_model(X.loc[4,:],y_log[4]),\n",
    "'five':run_OLS_model(X.loc[5,:],y_log[5]),\n",
    "'six':run_OLS_model(X.loc[6,:],y_log[6]),\n",
    "'seven':run_OLS_model(X.loc[7,:],y_log[7])\n",
    "} \n",
    "\n",
    "bracket_call_dict = {\n",
    "    'two':(X.loc[2,:],y_log[2]),\n",
    "    'three':(X.loc[3,:],y_log[3]),\n",
    "    'four':(X.loc[4,:],y_log[4]),\n",
    "    'five':(X.loc[5,:],y_log[5]),\n",
    "    'six':(X.loc[6,:],y_log[6]),\n",
    "    'seven':(X.loc[7,:],y_log[7])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stepwise selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepped_model_selections_dict = {}\n",
    "\n",
    "for k,v in bracket_call_dict.items():\n",
    "    stepwisers = stepwise_selection(v[0],v[1],v[0].columns,threshold_in=0.01, threshold_out = 0.05, verbose=False)\n",
    "    stepped_model_selections_dict[k] = stepwisers\n",
    "\n",
    "stepped_model_dict = {}\n",
    "\n",
    "for k,v in bracket_call_dict.items():\n",
    "    selection = stepped_model_selections_dict[k]\n",
    "    df = v[0][selection]\n",
    "    stepped_model_dict[k] = run_OLS_model(df,v[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_JB_dict = {}\n",
    "\n",
    "for k,v in stepped_model_dict.items():\n",
    "    resid = v.resid \n",
    "    name = ['Jarque-Bera','Prob','Skew', 'Kurtosis']\n",
    "    test = sms.jarque_bera(resid)\n",
    "    step_JB_dict[k] = list(zip(name, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two [('Jarque-Bera', 15150.128436396091), ('Prob', 0.0), ('Skew', -3.1233978454614575), ('Kurtosis', 19.49288492514398)]\n",
      "\n",
      "\n",
      "three [('Jarque-Bera', 32609.53321381114), ('Prob', 0.0), ('Skew', -2.116653974401343), ('Kurtosis', 9.867895781163663)]\n",
      "\n",
      "\n",
      "four [('Jarque-Bera', 99259.17533762459), ('Prob', 0.0), ('Skew', -3.003494388487013), ('Kurtosis', 22.016193618606174)]\n",
      "\n",
      "\n",
      "five [('Jarque-Bera', 142110.86060615702), ('Prob', 0.0), ('Skew', -6.467738389634934), ('Kurtosis', 86.20723545502742)]\n",
      "\n",
      "\n",
      "six [('Jarque-Bera', 3032.2679458406933), ('Prob', 0.0), ('Skew', -2.7154215628084764), ('Kurtosis', 17.27435894862614)]\n",
      "\n",
      "\n",
      "seven [('Jarque-Bera', 0.8525338585370891), ('Prob', 0.6529420295188015), ('Skew', 0.8516372406050681), ('Kurtosis', 2.286563614744315)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in step_JB_dict:\n",
    "    print(k,step_JB_dict[k])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV_model_selections_dict = {}\n",
    "\n",
    "for k,v in bracket_call_dict.items():\n",
    "    recursives = run_RFECV(v[0],v[1],select_rank=True)\n",
    "    RFECV_model_selections_dict[k] = recursives\n",
    "    \n",
    "RFECV_model_dict = {}\n",
    "\n",
    "for k,v in bracket_call_dict.items():\n",
    "    selection = RFECV_model_selections_dict[k]\n",
    "    df = v[0][selection]\n",
    "    RFECV_model_dict[k] = run_OLS_model(df,v[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV_JB_dict = {}\n",
    "\n",
    "for k,v in RFECV_model_dict.items():\n",
    "    resid = v.resid \n",
    "    name = ['Jarque-Bera','Prob','Skew', 'Kurtosis']\n",
    "    test = sms.jarque_bera(resid)\n",
    "    RFECV_JB_dict[k] = list(zip(name, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two [('Jarque-Bera', 14866.659475542403), ('Prob', 0.0), ('Skew', -3.1106307518964487), ('Kurtosis', 19.32525322386312)]\n",
      "\n",
      "\n",
      "three [('Jarque-Bera', 32463.535282623045), ('Prob', 0.0), ('Skew', -2.113125172169822), ('Kurtosis', 9.851006031305701)]\n",
      "\n",
      "\n",
      "four [('Jarque-Bera', 101179.42250548245), ('Prob', 0.0), ('Skew', -3.0216103769258655), ('Kurtosis', 22.206062285594673)]\n",
      "\n",
      "\n",
      "five [('Jarque-Bera', 137242.0647769978), ('Prob', 0.0), ('Skew', -6.327335654930235), ('Kurtosis', 84.77833579860493)]\n",
      "\n",
      "\n",
      "six [('Jarque-Bera', 3678.3014206837393), ('Prob', 0.0), ('Skew', -2.8047674715404782), ('Kurtosis', 18.858101426459353)]\n",
      "\n",
      "\n",
      "seven [('Jarque-Bera', 0.26281178427745444), ('Prob', 0.8768617908428157), ('Skew', 0.19875876393105746), ('Kurtosis', 2.0548931530497674)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in RFECV_JB_dict:\n",
    "    print(k,RFECV_JB_dict[k])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared, skew, kurt, Durbin-Watson, Jarque-Berra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(stepped_model.resid)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plots \n",
    "\n",
    "for feature in X_standardized.columns:\n",
    "    sm.qqplot(X_standardized[feature], line ='45')\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera','Prob','Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(resid)\n",
    "list(zip(name, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat X_hot with predictor and export as CSV for use in diagnosis and validation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.concat([y,X_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path  \n",
    "# filepath = Path('data/base_model.csv')  \n",
    "# filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "# export_df.to_csv(filepath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
