{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import simpreglib as srl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# for linear regression models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "\n",
    "# run_RFE and run_RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings # weird sns.distplot warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates dictionary of variance inflation factors. \n",
    "def create_vif_dictionary(X):\n",
    "\n",
    "    vif_dict = {}\n",
    "    for i in range(len(X.columns)):\n",
    "        vif = variance_inflation_factor(X.values, i)\n",
    "        v = X.columns[i]\n",
    "        vif_dict[v] = vif\n",
    "\n",
    "    good_vifs = []\n",
    "    bad_vifs = []\n",
    "\n",
    "    for k,v in vif_dict.items():\n",
    "        if v < 10:\n",
    "            good_vifs.append(k)\n",
    "        else:\n",
    "            bad_vifs.append(k)\n",
    "\n",
    "    return good_vifs,bad_vifs\n",
    "\n",
    "# create a dictionary showing the adjusted R-squared values for each feature individually\n",
    "def create_R2_dictionary(X,y):\n",
    "    adj_R_squares = {}\n",
    "    for feature in X.columns:\n",
    "        predictors_int = sm.add_constant(X[feature])\n",
    "        model = sm.OLS(y,predictors_int).fit()\n",
    "        adj_R_square = float(model.summary2().tables[0][3][0])\n",
    "        adj_R_squares[feature] = adj_R_square\n",
    "    return adj_R_squares\n",
    "\n",
    "# author's docstring is in a markup cell down below in the stepwise selection section\n",
    "def stepwise_selection(X, y, \n",
    "\n",
    "\n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            worst_feature_name = included[worst_feature]\n",
    "            included.pop(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature_name, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "def run_RFE(X,y):\n",
    "    linreg = LinearRegression()\n",
    "    selector = RFE(linreg)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    selected = selector.support_ # list of bools representing if feature is selected or not\n",
    "    selections = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(selected): # append labels of selected features to selections list\n",
    "        if feature == True:\n",
    "            selections.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ranked = selector.ranking_ # list of bools representing if feature is selected or not\n",
    "    rankers = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(ranked): # append labels of selected features to selections list\n",
    "        if feature == 1:\n",
    "            rankers.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    return selections, rankers\n",
    "\n",
    "def run_RFECV(X,y):\n",
    "    linreg = LinearRegression()\n",
    "    selector = RFECV(linreg)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    selected = selector.support_ # list of bools representing if feature is selected or not\n",
    "    selections = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(selected): # append labels of selected features to selections list\n",
    "        if feature == True:\n",
    "            selections.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ranked = selector.ranking_ # list of bools representing if feature is selected or not\n",
    "    rankers = [] # list of column names that are selected\n",
    "    labels = list(X.columns) # list of all column names \n",
    "\n",
    "    for idx,feature in enumerate(ranked): # append labels of selected features to selections list\n",
    "        if feature == 1:\n",
    "            rankers.append(labels[idx])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return selections, rankers\n",
    "\n",
    "def run_OLS_model(X,y):\n",
    "\n",
    "\n",
    "    predictors_int = sm.add_constant(X)\n",
    "    model = sm.OLS(y,predictors_int).fit()\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up predictor and target dataframes, deal with unusable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/kc_house_data.csv')\n",
    "X.drop(X.loc[X['sqft_basement']=='?'].index,inplace=True) # remove '?' from the data.\n",
    "y = X.price\n",
    "y_log = np.log(y) # target vairable log transformed for normality\n",
    "X.drop(['price','id','lat','long'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineer data to present as numerical values, not objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string types into np floats\n",
    "X.sqft_basement = [float(sq) for sq in list(X.sqft_basement)]\n",
    "\n",
    "# Replaces grade strings with numerics based on data dict. \n",
    "grade_raws = list(X.grade.unique())\n",
    "# replaces a cell value with the int of the first character of its existing string\n",
    "for raw in grade_raws:\n",
    "    X.grade.replace(to_replace=raw,value=int(raw[0]),inplace=True)\n",
    "\n",
    "# replaces condition objects with numerics based on data dict.\n",
    "condition_dict = {'Poor':1,'Fair':2,'Average':3,'Good':4,'Very Good':5}\n",
    "for key in condition_dict:\n",
    "    X.condition.replace(to_replace=condition_dict,inplace=True)\n",
    "\n",
    "# replace yr_built NaNs with numeric 0\n",
    "X.yr_renovated.replace(to_replace=np.nan,value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert waterfront into numeric boolean\n",
    "waterfront_bool_list = []\n",
    "for value in X.waterfront:\n",
    "    if value == 'YES':\n",
    "        waterfront_bool_list.append(1)\n",
    "    else:\n",
    "        waterfront_bool_list.append(0)\n",
    "X.waterfront = waterfront_bool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert view from string into categorical ordinal\n",
    "view_rank_list = [] \n",
    "view_dict = {'NONE':0,'FAIR':1,'AVERAGE':2,'GOOD':3,'EXCELLENT':4}\n",
    "\n",
    "for value in X.view:\n",
    "    if value in list(view_dict.keys()):\n",
    "        view_rank_list.append(view_dict[value])\n",
    "    else:\n",
    "        view_rank_list.append(0)\n",
    "        \n",
    "X.view = view_rank_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineer date into a usable type of number (datetime ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into ordinals\n",
    "X.date = pd.to_datetime(X['date'])\n",
    "X.date = X['date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dict = {} # creates dictionary where keys are the labels and values are the count of null values\n",
    "for feature in X.columns:\n",
    "    null_count = sum(X[feature].isna())\n",
    "    null_dict[feature] = null_count\n",
    "# null_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate multicolinearity before engineering inferred features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.corr()\n",
    "cor_df=X.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "cor_df['pairs'] = list(zip(cor_df.level_0, cor_df.level_1))\n",
    "cor_df.set_index(['pairs'], inplace = True)\n",
    "cor_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "cor_df.columns = ['cc']\n",
    "cor_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_df[(cor_df.cc>.60) & (cor_df.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colinear_drops = ['sqft_above','sqft_living15','bathrooms','sqft_lot15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineering inferred feature\n",
    "- bed bath ratio:           ratio of bedrooms to bathrooms\n",
    "- level ratios:             ratio of square feet above 'grade' and below (ratio of everything else to the basement)\n",
    "- live_lot_ratio:           ratio of living space to lot size\n",
    "- relative living space:    ratio of living space to the living space of the nearest 15 houses (sqft_living :: sqft_living15)\n",
    "- relatve lot size:         same as living space but for lot size instead. \n",
    "- level difference:         difference in square footage of living space to basement space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbratios = []\n",
    "lvl_ratios = []\n",
    "live_lot_ratio = []\n",
    "\n",
    "for index,row in X.iterrows(): #iterate through every record\n",
    "#     print(row)\n",
    "    bbratio = row.bedrooms/row.bathrooms # calculate ratio of bedrooms to bathrooms\n",
    "    bbratios.append(bbratio) # append ratio to the list\n",
    "\n",
    "    LLratio = row.sqft_living/row.sqft_lot\n",
    "    live_lot_ratio.append(LLratio)\n",
    "\n",
    "    if row.sqft_basement == 0: # sqft_basement is zero if there is no basement\n",
    "        lvl_ratios.append(0) # ratio should also be zero if there is no ratio\n",
    "    else:\n",
    "        lvl_ratio = row.sqft_above / row.sqft_basement # calculate ratio of space above grade vs below grade\n",
    "        lvl_ratios.append(lvl_ratio) # append ratio to the list\n",
    "\n",
    "X['bed_bath_ratio'] = bbratios # create new column and asign list as its values\n",
    "X['level_ratio'] = lvl_ratios # create new column and asign list as its values\n",
    "X['live_lot_ratio'] = live_lot_ratio # you get the idea . . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_live_space = []\n",
    "rel_lot_size = [] \n",
    "rel_difference = []\n",
    "\n",
    "for index,row in X.iterrows(): # for every record \n",
    "    live_dif = row.sqft_living - row.sqft_living15 # calculate difference in sqft of the given house and the nearest 15 other houses\n",
    "    rel_live_space.append(live_dif) # append it to the list\n",
    "\n",
    "    lot_dif = row.sqft_lot - row.sqft_lot15 # calculate difference in sqft of the given lot and the nearest 15 other lots\n",
    "    rel_lot_size.append(lot_dif) # append it to the list\n",
    "\n",
    "    lvl_dif = row.sqft_above - row.sqft_basement # calculate difference between space above grade and below grade\n",
    "    rel_difference.append(lvl_dif) # append it to the list\n",
    "\n",
    "X['relative_living_space'] = rel_live_space # assign respective list to new column \n",
    "X['relative_lot_size'] = rel_lot_size\n",
    "X['level_difference'] = rel_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_loc_dict = {'Duwamish':[98168],\n",
    "'Elliott Bay':[98119,98104,98129,98132,98127,98125,98195,98101,98134,98170,98139,98131,98181], \n",
    "'Puget Sound':[98071,98083,98013,98070,98031,98131,98063,98195,98207,98190], \n",
    "'Lake Union':[98109], \n",
    "'Ship Canal':[00000], \n",
    "'Lake Washington':[98072,98077], \n",
    "'Lake Sammamish':[98074,98075,98029], \n",
    "'other lake':[00000], \n",
    "'river/slough waterfronts':[00000]}\n",
    "\n",
    "waterfront_list = []\n",
    "\n",
    "for zip in X.zipcode:\n",
    "    for k,v in water_loc_dict.items():\n",
    "        if zip in v:\n",
    "            waterfront_list.append(k)\n",
    "            appended = True\n",
    "            break\n",
    "        else: \n",
    "            appended = False\n",
    "    if not appended:\n",
    "        waterfront_list.append('NONE')\n",
    "\n",
    "# print(len(waterfront_list),set(waterfront_list))\n",
    "X['waterfront_loc'] = waterfront_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_dummies = pd.get_dummies(X.waterfront_loc).drop('NONE',axis=1).add_prefix('waterfront_')\n",
    "\n",
    "X = X.drop(['waterfront_loc','zipcode'],axis=1)\n",
    "hot_water = pd.concat([X,waterfront_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot_water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>date</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>sqft_living</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>floors</td>\n",
       "      <td>floors</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           level_0        level_1    0\n",
       "0             date           date  1.0\n",
       "406  sqft_living15  sqft_living15  1.0\n",
       "87     sqft_living    sqft_living  1.0\n",
       "116       sqft_lot       sqft_lot  1.0\n",
       "145         floors         floors  1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df=hot_water.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "cor_df.head()\n",
    "# cor_df['pairs'] = list(zip(cor_df.level_0, cor_df.level_1))\n",
    "# cor_df.set_index(['pairs'], inplace = True)\n",
    "# cor_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "# cor_df.columns = ['cc']\n",
    "# cor_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_df[(cor_df.cc>.60) & (cor_df.cc <1)]\n",
    "\n",
    "# is it a good decision to drop sqft_living in lieu of relative_living_space ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop based one colinearity\n",
    "co_drops = ['sqft_living','sqft_above','sqft_living15','bathrooms','sqft_lot15','sqft_lot','level_ratio'] # included level ratio since its basically same as level difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = X.drop(co_drops,axis=1)\n",
    "# Xd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- investigage mapping zipcode, or coordinates to view ? Not enough coordinate info... \n",
    "- consider dropping zip/lot/long and then re running notebook from the top, (i.e. their presence may affect colinearity of other features?) \n",
    "    - did not affect colinearity but it cleaned up some clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Transformation and Feature ranking \n",
    "using standardization (x - x_bar / sigma) to normalize units of measurement\n",
    "\n",
    "investigate feature rankings using:\n",
    "- stepwise method\n",
    "- recursive elimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = pd.DataFrame([]) # data standardized\n",
    "for feature in Xd.columns:\n",
    "    x_comp = (Xd[feature] - np.mean(Xd[feature])/np.std(Xd[feature])) # (x - x_bar)/sigma\n",
    "    Xs[feature] = x_comp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlog = pd.DataFrame([]) # standardized data log transformed\n",
    "for feature in Xs.columns:\n",
    "    x_logged = np.log(Xs[feature])\n",
    "    Xlog[feature] = x_logged\n",
    "\n",
    "# dealing with NaN values resulting from the log transformation\n",
    "for column in Xlog:\n",
    "    Xlog[column].replace(np.NaN,0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline model for refrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_base = run_OLS_model(Xd,y_log)\n",
    "y_log_pred_stand = run_OLS_model(Xs,y_log)\n",
    "# y_log_pred_log = run_OLS_model(Xlog,y_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plots \n",
    "# for idx,feature in enumerate(Xs.columns):\n",
    "#     logged = np.log(Xs[feature])\n",
    "#     sm.qqplot(logged, line ='45')\n",
    "#     plt.title(feature)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stepwise selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwisers = stepwise_selection(Xd, y_log, Xd.columns,threshold_in=0.01, threshold_out = 0.05, verbose=False)\n",
    "stepwised_df = Xd[stepwisers]\n",
    "\n",
    "# appears same as baseline \n",
    "stepped_model = run_OLS_model(stepwised_df,y_log)\n",
    "stepped_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode grade\n",
    "# inspect multicolinearity once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# lb = LabelBinarizer()\n",
    "# condition_dummies = lb.fit_transform(stepwised_df.condition)\n",
    "# # You need to convert this back to a dataframe\n",
    "# con_dum_df = pd.DataFrame(condition_dummies,columns=lb.classes_).add_prefix('condition_')\n",
    "\n",
    "# step_coded = pd.concat([stepwised_df,con_dum_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_df=step_coded.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "# cc_df['pairs'] = list(zip(cc_df.level_0, cc_df.level_1))\n",
    "# cc_df.set_index(['pairs'], inplace = True)\n",
    "# cc_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "# cc_df.columns = ['cc']\n",
    "# cc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# cc_df[(cc_df.cc>.60) & (cc_df.cc <1)] # drop condition_4, condition_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_coded = pd.concat([y_log,step_coded],axis=1)\n",
    "# step_coded = step_coded.drop(['condition_4','condition_3','condition_1','condition_2','condition_5'],axis=1)\n",
    "# step_coded = step_coded.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nanf_dict = {}\n",
    "\n",
    "for feature in hot_stepped.columns:\n",
    "    Nanf_dict[feature] = sum(hot_stepped[feature].isna())\n",
    "\n",
    "Nanf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_step_model = run_OLS_model(hot_stepped,y_log)\n",
    "hot_step_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive elimation: with and without cross-validation\n",
    "- does not produce better results than stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected, ranking = run_RFECV(Xd,y_log)\n",
    "RFECV_df = Xd[selected]\n",
    "\n",
    "# also identtical to baseline \n",
    "rfe_model = run_OLS_model(RFECV_df,y_log)\n",
    "# rfe_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual selection based on P value and variance inflation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good,bad = create_vif_dictionary(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
