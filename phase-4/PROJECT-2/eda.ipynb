{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains chest x-ray images some of which are labeled as 'NORMAL' and otheras as 'PNEUMONIA' which are examples of patients that indeed have a case the potentially lethal respiratory infection. There are 5656 total images in a range of dimensions and all are greyscale. The dataset is sourced directly from [this Kaggle page](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia) using the Kaggle API command (kaggle datasets download -d paultimothymooney/chest-xray-pneumonia). This kaggle page cites [Mendeley Data](https://data.mendeley.com/datasets/rscbjbr9sj/2) as its original data source.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and sifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependences for data loading and sifting\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths to data directories\n",
    "train_dir = \"data/train/\"\n",
    "test_dir = \"data/test/\"\n",
    "val_dir = \"data/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classs balance for Train sample (Normal, Pneumonia):  0.3460645161290323\n",
      "Classs balance for Test sample (Normal, Pneumonia):  0.6\n",
      "Classs balance for Validation sample (Normal, Pneumonia):  1.0\n",
      "Sampling distribution (train,test,val):  (0.8907103825136612, 0.10655737704918032, 0.00273224043715847)\n"
     ]
    }
   ],
   "source": [
    "# calculate class balance for each sample\n",
    "train_class_balance = (len(os.listdir(train_dir+\"NORMAL\")),len(os.listdir(train_dir+\"PNEUMONIA\")))\n",
    "test_class_balance = (len(os.listdir(test_dir+\"NORMAL\")),len(os.listdir(test_dir+\"PNEUMONIA\")))\n",
    "val_class_balance = (len(os.listdir(val_dir+\"NORMAL\")),len(os.listdir(val_dir+\"PNEUMONIA\")))\n",
    "\n",
    "# calculate volume for each sample\n",
    "train_total = len(os.listdir(train_dir+\"NORMAL\"))+len(os.listdir(train_dir+\"PNEUMONIA\"))\n",
    "test_total = len(os.listdir(test_dir+\"NORMAL\"))+len(os.listdir(test_dir+\"PNEUMONIA\"))\n",
    "val_total = len(os.listdir(val_dir+\"NORMAL\"))+len(os.listdir(val_dir+\"PNEUMONIA\"))\n",
    "\n",
    "# calculate distribution of data volume between samples\n",
    "sample_balance = (train_total,test_total,val_total)\n",
    "\n",
    "\n",
    "print(\"Classs balance for Train sample (Normal, Pneumonia): \",train_class_balance[0]/train_class_balance[1])\n",
    "print(\"Classs balance for Test sample (Normal, Pneumonia): \",test_class_balance[0]/test_class_balance[1])\n",
    "print(\"Classs balance for Validation sample (Normal, Pneumonia): \",val_class_balance[0]/val_class_balance[1])\n",
    "print(\"Sampling distribution (train,test,val): \",(train_total/sum(sample_balance),test_total/sum(sample_balance),val_total/sum(sample_balance)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes already labeled and split for 3 way validation. The Train sample is, naturally, the largest of the 3 with over five thousand images, 66% of which are cases of pneumonia which will be the target prediction. The next largest is the test sample with over six hundred images of which 40% are trues cases of pneumonia. Finally, the validation set contains 16 images with each class being represented equally at 50%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Can the images be displayed easily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of (first) and Normal x-ray scan and (second) and x-ray scan showing pneumonia\n",
    "Image.open(\"data/train/NORMAL/IM-0115-0001.jpeg\").show()\n",
    "Image.open(\"data/train/PNEUMONIA/person1001_bacteria_2932.jpeg\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: is the data ready to fit a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for modeling\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# instatiating a data degenerater for each split sample \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "                                   \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_datagen.flow_from_directory(\n",
    "                       train_dir,\n",
    "                       target_size=(150,150),\n",
    "                       batch_size=16,\n",
    "                       class_mode='binary',\n",
    "                       color_mode='grayscale')\n",
    "\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "                      test_dir,\n",
    "                      target_size=(150,150),\n",
    "                      batch_size=16,\n",
    "                      class_mode='binary',\n",
    "                      color_mode='grayscale')\n",
    "\n",
    "val_data_generator = val_datagen.flow_from_directory(\n",
    "                     val_dir,\n",
    "                     target_size=(150,150),\n",
    "                     batch_size=16,\n",
    "                     class_mode='binary',\n",
    "                     color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple convultional neural network\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,1)))\n",
    "base_model.add(layers.MaxPooling2D((2, 2)))\n",
    "base_model.add(layers.Flatten())\n",
    "base_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model from above\n",
    "base_model.compile(loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 12s 465ms/step - loss: 1.2679 - acc: 0.6725 - val_loss: 0.7709 - val_acc: 0.5958\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 10s 387ms/step - loss: 0.4802 - acc: 0.7925 - val_loss: 0.4146 - val_acc: 0.8083\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 10s 380ms/step - loss: 0.3592 - acc: 0.8500 - val_loss: 1.0781 - val_acc: 0.5917\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.2379 - acc: 0.9125 - val_loss: 0.2722 - val_acc: 0.9083\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.2137 - acc: 0.9225 - val_loss: 0.3865 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1705 - acc: 0.9425 - val_loss: 0.4427 - val_acc: 0.7750\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.1776 - acc: 0.9325 - val_loss: 0.3138 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.1339 - acc: 0.9525 - val_loss: 0.5977 - val_acc: 0.7292\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1350 - acc: 0.9550 - val_loss: 0.6495 - val_acc: 0.7042\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1334 - acc: 0.9400 - val_loss: 0.7764 - val_acc: 0.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26caf355d60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training data and validate with the test sample\n",
    "base_model.fit(train_data_generator, \n",
    "               batch_size=16,\n",
    "               epochs=10,\n",
    "               steps_per_epoch=25,\n",
    "               validation_data=test_data_generator,\n",
    "               validation_steps=15\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlcusion \n",
    "The base model succesfully compiles and fits without any errors or warnings. The model also performs decently for a baseline model. I will continue tuning and optimizing thhe model in the [modeling notebook](/PROJECT-2/modeling.ipynb).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('learn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eb6b2671ae257969e1e6d572d1bfd2dc1c23f390a7081d26c146f9b82ef978d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
