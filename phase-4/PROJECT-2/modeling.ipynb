{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependences for data loading and sifting\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths to data directories\n",
    "train_dir = \"data/train/\"\n",
    "test_dir = \"data/test/\"\n",
    "val_dir = \"data/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# instatiating a data degenerater for each split sample \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "                                   \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_datagen.flow_from_directory(\n",
    "                       train_dir,\n",
    "                       target_size=(150,150),\n",
    "                       batch_size=16,\n",
    "                       class_mode='binary',\n",
    "                       color_mode='grayscale')\n",
    "\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "                      test_dir,\n",
    "                      target_size=(150,150),\n",
    "                      batch_size=16,\n",
    "                      class_mode='binary',\n",
    "                      color_mode='grayscale')\n",
    "\n",
    "val_data_generator = val_datagen.flow_from_directory(\n",
    "                     val_dir,\n",
    "                     target_size=(150,150),\n",
    "                     batch_size=16,\n",
    "                     class_mode='binary',\n",
    "                     color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Beginning a convolutional neural network with the most simple architecture for the sake of efficient diagnostics and optimization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture begins with a convolutional 2D layers, followed by a pooling layer, flattened, and then followed up with two dense layers.  \n",
    "THe model is compiled using binary cross entropy to measure the loss function and accuracy foor the performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here; design and compile the model\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,1)))\n",
    "base_model.add(layers.MaxPooling2D((2, 2)))\n",
    "base_model.add(layers.Flatten())\n",
    "base_model.add(layers.Dense(512, activation='relu'))\n",
    "base_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "base_model.compile(loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the compiled base model is now fit very lean, using 10 steps per epoch and 5 total epochs, the test data set is used for validation as the actual validation sample is extremely small and reserved only for the final phase of performance evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.4038 - acc: 0.8562 - val_loss: 0.6068 - val_acc: 0.7167\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2617 - acc: 0.9187 - val_loss: 0.5568 - val_acc: 0.7750\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.2517 - acc: 0.9062 - val_loss: 0.3020 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.1205 - acc: 0.9500 - val_loss: 0.4314 - val_acc: 0.8083\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.2201 - acc: 0.9250 - val_loss: 0.9969 - val_acc: 0.6917\n"
     ]
    }
   ],
   "source": [
    "base_model_results = base_model.fit(train_data_generator, \n",
    "                              steps_per_epoch=10, \n",
    "                              epochs=5, \n",
    "                              validation_data=test_data_generator, \n",
    "                              validation_steps=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base model begins stronger than expected with an accuracy of 74% on the test data. A good start, with plenty of room to improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('learn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eb6b2671ae257969e1e6d572d1bfd2dc1c23f390a7081d26c146f9b82ef978d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
