{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# APIs - Cumulative Lab\n", "\n", "\n", "## Introduction \n", "\n", "We've seen how the Yelp API works and how to create basic visualizations using Folium. It's time to put those skills to work in order to create a working map! Taking things a step further, you'll also independently explore how to perform pagination in order to retrieve a full results set from the Yelp API.\n", "\n", "## Objectives\n", "\n", "You will be able to: \n", "\n", "* Practice using functions to organize your code\n", "* Use pagination to retrieve all results from an API query\n", "* Practice parsing data returned from an API query\n", "* Practice interpreting visualizations of a dataset\n", "* Create maps using Folium"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Your Task: Query Yelp for All Businesses in a Category and Analyze the Results\n", "\n", "![restaurant counter with pizza](images/restaurant_counter.jpg)\n", "\n", "Photo by <a href=\"https://unsplash.com/@jordanmadrid?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Jordan Madrid</a> on <a href=\"/s/photos/pizza-restaurant?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Overview\n", "\n", "You've now worked with some API calls, but we have yet to see how to retrieve a more complete dataset in a programmatic manner. In this lab, you will write a query of businesses on Yelp, then use *pagination* to retrieve all possible results for that query. Then you will create a summary of your findings, including a Folium map of the geographic locations of those businesses.\n", "\n", "### Technical Details\n", "\n", "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the **API limits**. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a **maximum of 50 results per request** and defaults to 20. Furthermore, any search will be limited to a **total of 1000 results**. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retrieving 50 at a time. Processes such as these are often referred to as pagination.\n", "\n", "Also, be mindful of the **API** ***rate*** **limits**. You can only make **5000 requests per day** and are also can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use `time.sleep(n)` to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.\n", "\n", "In this lab, you will define a search and then paginate over the results to retrieve all of the results. You'll then parse these responses as a list of dictionaries (for further exploration) and create a map using Folium to visualize the results geographically.\n", "\n", "### Requirements\n", "\n", "#### 1. Make the Initial Request\n", "\n", "Start by filling in your API key to make the initial request to the business search API. Investigate the structure of the response you get back and start figuring out how you will extract the relevant information.\n", "\n", "#### 2. Add Pagination\n", "\n", "Using loops and functions, collect the maximum number of results for your query from the API.\n", "\n", "#### 3. Perform Exploratory Analysis\n", "\n", "Interpret visualizations related to the price range, average rating, and number of reviews for all query results.\n", "\n", "#### 4. Create a Folium Map\n", "\n", "Using latitude and longitude data, plot the query results on an interactive map."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Make the Initial Request\n", "\n", "### Querying\n", "\n", "Start by making an initial request to the Yelp API. Your search must include at least 2 parameters: **term** and **location**. For example, you might search for pizza restaurants in NYC. The term and location is up to you but make the request below.\n", "\n", "Use the `requests` library ([documentation here](https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request)).\n", "\n", "You'll also need an API key from Yelp. If you haven't done this already, go to the Yelp [Manage App page](https://www.yelp.com/developers/v3/manage_app) and create a new app (after making an account if you haven't already)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Import the requests library\n", "None\n", "\n", "# Get this from the \"Manage App\" page. Make sure you set them\n", "# back to None before pushing this to GitHub, since otherwise\n", "# your credentials will be compromised\n", "api_key = None\n", "\n", "# These can be whatever you want! But the solution uses \"pizza\"\n", "# and \"New York NY\" if you want to compare your work directly\n", "term = None\n", "location = None\n", "\n", "# Set up params for request\n", "url = \"https://api.yelp.com/v3/businesses/search\"\n", "headers = {\n", "    \"Authorization\": \"Bearer {}\".format(api_key)\n", "}\n", "url_params = {\n", "    \"term\": term.replace(\" \", \"+\"),\n", "    \"location\": location.replace(\" \", \"+\")\n", "}\n", "\n", "# Make the request using requests.get, passing in\n", "# url, headers=headers, and params=url_params\n", "response = None\n", "\n", "# Confirm we got a 200 response\n", "response"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# Get the response body in JSON format\n", "response_json = response.json()\n", "# View the keys\n", "response_json.keys()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Extracting Data\n", "\n", "Now, retrieve the value associated with the `'businesses'` key, and inspect its contents."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Retrieve the value from response_json\n", "businesses = None\n", "\n", "# View the first 2 records\n", "businesses[:2]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Preparing Data\n", "\n", "Write a function `prepare_data` that takes in a list of dictionaries like `businesses` and returns a copy that has been prepared for analysis:\n", "\n", "1. The `coordinates` key-value pair has been converted into two separate key-value pairs, `latitude` and `longitude`\n", "2. All other key-value pairs except for `name`, `review_count`, `rating`, and `price` have been dropped\n", "3. All dictionaries missing one of the relevant keys or containing null values have been dropped\n", "\n", "In other words, the final keys for each dictionary should be `name`, `review_count`, `rating`, `price`, `latitude`, and `longitude`.\n", "\n", "Complete the function in the cell below:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "def prepare_data(data_list):\n", "    \"\"\"\n", "    This function takes in a list of dictionaries and prepares it\n", "    for analysis\n", "    \"\"\"\n", "    \n", "    # Make a new list to hold results\n", "    results = []\n", "    \n", "    for business_data in data_list:\n", "    \n", "        # Make a new dictionary to hold prepared data for this business\n", "        prepared_data = {}\n", "        \n", "        # Extract name, review_count, rating, and price key-value pairs\n", "        # from business_data and add to prepared_data\n", "        # If a key is not present in business_data, add it to prepared_data\n", "        # with an associated value of None\n", "        None\n", "    \n", "        # Parse and add latitude and longitude columns\n", "        None\n", "        \n", "        # Add to list if all values are present\n", "        if all(prepared_data.values()):\n", "            results.append(prepared_data)\n", "    \n", "    return results\n", "    \n", "# Test out function\n", "prepared_businesses = prepare_data(businesses)\n", "prepared_businesses[:5]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check that your function created the correct keys:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "assert sorted(list(prepared_businesses[0].keys())) == ['latitude', 'longitude', 'name', 'price', 'rating', 'review_count']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following code will differ depending on your query, but we expect there to be 20 businesses in the original list, and potentially fewer in the prepared list (if any of them were missing data):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "print(\"Original:\", len(businesses))\n", "print(\"Prepared:\", len(prepared_businesses))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great! We will reuse this function once we have retrieved the full dataset."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Add Pagination\n", "\n", "Now that you are able to extract information from one page of the response, let's figure out how to request as many pages as possible.\n", "\n", "### Determining the Total\n", "\n", "Depending on the number of total results for your query, you will either retrieve all of the results, or just the first 1000 (if there are more than 1000 total).\n", "\n", "We can find the total number of results using the `\"total\"` key:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "response_json[\"total\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["(This is specific to the implementation of the Yelp API. Some APIs will just tell you that there are more pages, or will tell you the number of pages total, rather than the total number of results. If you're not sure, always check the documentation.)\n", "\n", "In the cell below, assign the variable `total` to either the value shown above (if it is less than 1000), or 1000."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "total = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculating the Offsets\n", "\n", "The documentation states in the parameters section:\n", "\n", "> **Name**: `limit`, **Type:** int, **Description:** Optional. Number of business results to return. By default, it will return 20. Maximum is 50.\n", "\n", "> **Name**: `offset`, **Type:** int, **Description:** Optional. Offset the list of returned business results by this amount.\n", "\n", "So, to get the most results with the fewest API calls we want to set a limit of 50 every time. If, say, we wanted to get 210 total results, that would mean:\n", "\n", "1. Offset of `0` (first 50 records)\n", "2. Offset of `50` (second 50 records)\n", "3. Offset of `100` (third 50 records)\n", "4. Offset of `150` (fourth 50 records)\n", "5. Offset of `200` (final 10 records)\n", "\n", "In the cell below, create a function `get_offsets` that takes in a total and returns a list of offsets for that total. You can assume that there is a limit of 50 every time.\n", "\n", "*Hint: you can use `range` ([documentation here](https://docs.python.org/3.3/library/stdtypes.html?highlight=range#range)) to do this in one line of code. Just make the returned result is a list.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "def get_offsets(total):\n", "    \"\"\"\n", "    Get a list of offsets needed to get all pages\n", "    of data up until the total\n", "    \"\"\"\n", "    None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check that your function works below:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "assert get_offsets(200) == [0, 50, 100, 150]\n", "assert get_offsets(210) == [0, 50, 100, 150, 200]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Putting It All Together\n", "\n", "Recall that the following variable has already been declared for you:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "url_params"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll go ahead and also specify that the limit should be 50 every time:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "url_params[\"limit\"] = 50"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to modify the offset, you'll need to add it to `url_params` with the key `\"offset\"` and whatever value is needed.\n", "\n", "In the cell below, write code that:\n", "\n", "* Creates an empty list for the full prepared dataset\n", "* Loops over all of the offsets from `get_offsets` and makes an API call each time with the specified offset\n", "* Calls `prepare_data` to get a cleaned version of the result of each API call\n", "* Extends the full prepared dataset list with each query's prepared dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Create an empty list for the full prepared dataset\n", "full_dataset = None\n", "\n", "for offset in get_offsets(total):\n", "    # Add or update the \"offset\" key-value pair in url_params\n", "    None\n", "    \n", "    # Make the query and get the response\n", "    response = requests.get(url, headers=headers, params=url_params)\n", "    \n", "    # Get the response body in JSON format\n", "    response_json = None\n", "    \n", "    # Get the list of businesses from the response_json\n", "    businesses = None\n", "    \n", "    # Call the prepare_data function to get a list of processed data\n", "    prepared_businesses = None\n", "    \n", "    # Extend full_dataset with this list (don't append, or you'll get\n", "    # a list of lists instead of a flat list)\n", "    None\n", "\n", "# Check the length of the full dataset. It will be up to `total`,\n", "# potentially less if there were missing values\n", "len(full_dataset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This code may take up to a few minutes to run.\n", "\n", "If you get an error trying to get the response body in JSON format, try adding `time.sleep(1)` right after the `requests.get` line, so your code will sleep for 1 second between each API call."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Perform Exploratory Analysis\n", "\n", "Take the businesses from the previous question and do an initial exploratory analysis. We have provided some plots for you to interpret:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "from collections import Counter\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(16, 5))\n", "\n", "# Plot distribution of number of reviews\n", "all_review_counts = [x[\"review_count\"] for x in full_dataset]\n", "ax1.hist(all_review_counts)\n", "ax1.set_title(\"Review Count Distribution\")\n", "ax1.set_xlabel(\"Number of Reviews\")\n", "ax1.set_ylabel(\"Number of Businesses\")\n", "\n", "# Plot rating distribution\n", "all_ratings = [x[\"rating\"] for x in full_dataset]\n", "rating_counter = Counter(all_ratings)\n", "rating_keys = sorted(rating_counter.keys())\n", "ax2.bar(rating_keys, [rating_counter[key] for key in rating_keys])\n", "ax2.set_title(\"Rating Distribution\")\n", "ax2.set_xlabel(\"Rating\")\n", "ax2.set_ylabel(\"Number of Businesses\")\n", "\n", "# Plot price distribution\n", "all_prices = [x[\"price\"].replace(\"$\", r\"\\$\") for x in full_dataset]\n", "price_counter = Counter(all_prices)\n", "price_keys = sorted(price_counter.keys())\n", "ax3.bar(price_keys, [price_counter[key] for key in price_keys])\n", "ax3.set_title(\"Price Distribution\")\n", "ax3.set_xlabel(\"Price Category\")\n", "ax3.set_ylabel(\"Number of Businesses\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Describe the distributions displayed above and interpret them in the context of your query. (Your answer may differ from the solution branch depending on your query.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the cell below, we also plot the rating distributions by price. In this setup, a price of one dollar sign is \"lower price\" and everything else is \"higher price\"."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "higher_price = []\n", "lower_price = []\n", "for row in full_dataset:\n", "    if row[\"price\"] == \"$\":\n", "        lower_price.append(row[\"rating\"])\n", "    else:\n", "        higher_price.append(row[\"rating\"])\n", "        \n", "fig, ax = plt.subplots()\n", "\n", "ax.hist([higher_price, lower_price], label=[\"higher price\", \"lower price\"], density=True)\n", "\n", "ax.legend();"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Is a higher price associated with a higher rating? (No need for any additional math/statistics, just interpret what you see in the plot.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, let's look at ratings vs. review counts:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "fig, ax = plt.subplots(figsize=(16,5))\n", "\n", "ax.scatter(all_review_counts, all_ratings, alpha=0.2)\n", "ax.set_xlabel(\"Number of Reviews\")\n", "ax.set_ylabel(\"Rating\")\n", "# \"zoom in\" to a subset of review counts\n", "ax.set_xlim(left=0, right=1000);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Is a higher number of reviews associated with a higher rating?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Create a Folium Map\n", "\n", "Make a map using Folium of the businesses you retrieved. Be sure to also add popups to the markers giving some basic information such as name, rating and price.\n", "\n", "You can center the map around the latitude and longitude of the first item in `full_dataset`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Import the library\n", "None\n", "\n", "# Set up center latitude and longitude\n", "center_lat = None\n", "center_long = None\n", "\n", "# Initialize map with center lat and long\n", "yelp_map = None\n", "\n", "# Adjust this limit to see more or fewer businesses\n", "limit=100\n", "\n", "for business in full_dataset[:limit]:\n", "    # Extract information about business\n", "    lat = None\n", "    long = None\n", "    name = None\n", "    rating = None\n", "    price = None\n", "    details = \"{}\\nPrice: {} Rating:{}\".format(name,price,rating)\n", "    \n", "    # Create popup with relevant details\n", "    popup = None\n", "    \n", "    # Create marker with relevant lat/long and popup\n", "    marker = None\n", "    \n", "    marker.add_to(yelp_map)\n", "    \n", "yelp_map"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "Nice work! In this lab, you've made multiple API calls to Yelp in order to paginate through a results set, performing some basic exploratory analysis and then creating a nice interactive map to display the results using Folium! Well done!"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}