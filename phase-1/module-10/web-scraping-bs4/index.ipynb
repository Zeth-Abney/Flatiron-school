{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen a more extensive example of developing a web scraping script, it's time to further practice and formalize that knowledge by writing functions to parse specific pieces of information from the web page and then synthesizing these into a larger loop that will iterate over successive web pages in order to build a complete dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Navigate HTML documents using Beautiful Soup's children and sibling relations\n",
    "* Select specific elements from HTML using Beautiful Soup\n",
    "* Use regular expressions to extract items with a certain pattern within Beautiful Soup\n",
    "* Determine the pagination scheme of a website and scrape multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "This lab will build upon the previous lesson. In the end, you'll look to write a script that will iterate over all of the pages for the demo site and extract the title, price, star rating and availability of each book listed. Building up to that, you'll formalize the concepts from the lesson by writing functions that will extract a list of each of these features for each web page. You'll then combine these functions into the full script which will look something like this:  \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame()\n",
    "for i in range(2,51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    new_titles = retrieve_titles(soup)\n",
    "    new_star_ratings = retrieve_ratings(soup)\n",
    "    new_prices = retrieve_prices(soup)\n",
    "    new_avails = retrieve_avails(soup)\n",
    "    ...\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Titles\n",
    "\n",
    "To start, write a function that extracts the titles of the books on a given page. The input for the function should be the `soup` for the HTML of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_23360/11285091.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\zethu\\AppData\\Local\\Temp/ipykernel_23360/11285091.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    return final_titles = final_titles\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def retrieve_titles(book_soup):\n",
    "    titles = book_soup.findAll('h3')\n",
    "    final_titles = [book.find('a').attrs['title'] for book in book_soup.findAll('h3')]\n",
    "#     print(final_titles)\n",
    "    return final_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Light in the Attic',\n",
       " 'Tipping the Velvet',\n",
       " 'Soumission',\n",
       " 'Sharp Objects',\n",
       " 'Sapiens: A Brief History of Humankind',\n",
       " 'The Requiem Red',\n",
       " 'The Dirty Little Secrets of Getting Your Dream Job',\n",
       " 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull',\n",
       " 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics',\n",
       " 'The Black Maria',\n",
       " 'Starving Hearts (Triangular Trade Trilogy, #1)',\n",
       " \"Shakespeare's Sonnets\",\n",
       " 'Set Me Free',\n",
       " \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\",\n",
       " 'Rip it Up and Start Again',\n",
       " 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991',\n",
       " 'Olio',\n",
       " 'Mesaerion: The Best Science Fiction Stories 1800-1849',\n",
       " 'Libertarianism for Beginners',\n",
       " \"It's Only the Himalayas\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_titles(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23360/1561700365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_titles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_titles' is not defined"
     ]
    }
   ],
   "source": [
    "print(final_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Ratings\n",
    "\n",
    "Next, write a similar function to retrieve the star ratings on a given page. Again, the function should take in the `soup` from the given HTML page and return a list of the star ratings for the books. These star ratings should be formatted as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ratings(book_soup):\n",
    "    star_ratings = []\n",
    "    star_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    regex = re.compile(\"star-rating (.*)\")\n",
    "    for r in book_soup.findAll('p', {\"class\" : regex}):\n",
    "        star_ratings.append(r.attrs['class'][-1])\n",
    "    star_ratings = [star_dict[s] for s in star_ratings]\n",
    "#     print(star_ratings)\n",
    "    return star_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Prices\n",
    "\n",
    "Now write a function to retrieve the prices on a given page. The function should take in the `soup` from the given page and return a list of prices formatted as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_prices(book_soup):\n",
    "    prices = [float(p.text[1:]) for p in book_soup.findAll('p', class_=\"price_color\")]\n",
    "#     print(prices)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Availability\n",
    "\n",
    "Write a function to retrieve whether each book is available or not. The function should take in the `soup` from a given html page and return a list of the availability for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_availabilities(book_soup):\n",
    "    avails = [a.text.strip() for a in book_soup.findAll('p', class_=\"instock availability\")]\n",
    "#     print(avails)\n",
    "    return avails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Script to Retrieve All the Books From All 50 Pages\n",
    "\n",
    "Finally, write a script to retrieve all of the information from all 50 pages of the books.toscrape.com website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_page = requests.get('http://books.toscrape.com/')\n",
    "\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Star_Rating</th>\n",
       "      <th>Price_(pounds)</th>\n",
       "      <th>Availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forever Rockers (The Rocker #12)</td>\n",
       "      <td>3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fighting Fate (Fighting #6)</td>\n",
       "      <td>3</td>\n",
       "      <td>39.24</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma</td>\n",
       "      <td>2</td>\n",
       "      <td>32.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eat, Pray, Love</td>\n",
       "      <td>3</td>\n",
       "      <td>51.32</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.53</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)</td>\n",
       "      <td>4</td>\n",
       "      <td>57.06</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n",
       "      <td>5</td>\n",
       "      <td>16.97</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1st to Die (Women's Murder Club #1)</td>\n",
       "      <td>1</td>\n",
       "      <td>53.98</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1,000 Places to See Before You Die</td>\n",
       "      <td>5</td>\n",
       "      <td>26.08</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title Star_Rating  \\\n",
       "0                                         Frankenstein           2   \n",
       "1                     Forever Rockers (The Rocker #12)           3   \n",
       "2                          Fighting Fate (Fighting #6)           3   \n",
       "3                                                 Emma           2   \n",
       "4                                      Eat, Pray, Love           3   \n",
       "..                                                 ...         ...   \n",
       "995  Alice in Wonderland (Alice's Adventures in Won...           1   \n",
       "996   Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)           4   \n",
       "997  A Spy's Devotion (The Regency Spies of London #1)           5   \n",
       "998                1st to Die (Women's Murder Club #1)           1   \n",
       "999                 1,000 Places to See Before You Die           5   \n",
       "\n",
       "    Price_(pounds) Availability  \n",
       "0             38.0     In stock  \n",
       "1             28.8     In stock  \n",
       "2            39.24     In stock  \n",
       "3            32.93     In stock  \n",
       "4            51.32     In stock  \n",
       "..             ...          ...  \n",
       "995          55.53     In stock  \n",
       "996          57.06     In stock  \n",
       "997          16.97     In stock  \n",
       "998          53.98     In stock  \n",
       "999          26.08     In stock  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "final_titles = []\n",
    "star_ratings = []\n",
    "prices = []\n",
    "avails = []\n",
    "\n",
    "for i in range(1,51):\n",
    "    if i == 1:\n",
    "        url = 'http://books.toscrape.com/'\n",
    "    else:\n",
    "        url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#     book_soup = soup.find('ol', class_=\"row\")\n",
    "    final_titles += retrieve_titles(book_soup)       #final_titles, list of strings\n",
    "    star_ratings += retrieve_ratings(book_soup)      #ratings, lsit of ints\n",
    "    prices += retrieve_prices(book_soup)             #prices, list of floats\n",
    "    avails += retrieve_availabilities(book_soup)     #avails, list of strings\n",
    "\n",
    "\n",
    "book_frame = pd.DataFrame([final_titles, star_ratings, prices, avails]).transpose()\n",
    "book_frame.columns = ['Title', 'Star_Rating', 'Price_(pounds)', 'Availability']\n",
    "book_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up: Write a new version of the script you just wrote. \n",
    "\n",
    "If you used URL hacking to generate each successive page URL, instead write a function that retrieves the link from the `\"next\"` button at the bottom of the page. Conversely, if you already used this approach above, use URL-hacking (arguably the easier of the two methods in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Star_Rating</th>\n",
       "      <th>Price_(pounds)</th>\n",
       "      <th>Availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forever Rockers (The Rocker #12)</td>\n",
       "      <td>3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fighting Fate (Fighting #6)</td>\n",
       "      <td>3</td>\n",
       "      <td>39.24</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma</td>\n",
       "      <td>2</td>\n",
       "      <td>32.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eat, Pray, Love</td>\n",
       "      <td>3</td>\n",
       "      <td>51.32</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n",
       "      <td>1</td>\n",
       "      <td>55.53</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)</td>\n",
       "      <td>4</td>\n",
       "      <td>57.06</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n",
       "      <td>5</td>\n",
       "      <td>16.97</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>1st to Die (Women's Murder Club #1)</td>\n",
       "      <td>1</td>\n",
       "      <td>53.98</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>1,000 Places to See Before You Die</td>\n",
       "      <td>5</td>\n",
       "      <td>26.08</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title Star_Rating  \\\n",
       "0                                          Frankenstein           2   \n",
       "1                      Forever Rockers (The Rocker #12)           3   \n",
       "2                           Fighting Fate (Fighting #6)           3   \n",
       "3                                                  Emma           2   \n",
       "4                                       Eat, Pray, Love           3   \n",
       "...                                                 ...         ...   \n",
       "3015  Alice in Wonderland (Alice's Adventures in Won...           1   \n",
       "3016   Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)           4   \n",
       "3017  A Spy's Devotion (The Regency Spies of London #1)           5   \n",
       "3018                1st to Die (Women's Murder Club #1)           1   \n",
       "3019                 1,000 Places to See Before You Die           5   \n",
       "\n",
       "     Price_(pounds) Availability  \n",
       "0              38.0     In stock  \n",
       "1              28.8     In stock  \n",
       "2             39.24     In stock  \n",
       "3             32.93     In stock  \n",
       "4             51.32     In stock  \n",
       "...             ...          ...  \n",
       "3015          55.53     In stock  \n",
       "3016          57.06     In stock  \n",
       "3017          16.97     In stock  \n",
       "3018          53.98     In stock  \n",
       "3019          26.08     In stock  \n",
       "\n",
       "[3020 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "# final_titles = []\n",
    "# star_ratings = []\n",
    "# prices = []\n",
    "# avails = []\n",
    "\n",
    "def get_next_page(soup):\n",
    "    next_button = soup.find(\"li\", class_=\"next\") #May return none if on final page\n",
    "    if next_button:\n",
    "        return next_button.find('a').attrs['href']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_url(url, final_titles=[], star_ratings=[], prices=[], avails=[]):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#     book_soup = soup.find('ol', class_=\"row\")\n",
    "    final_titles += retrieve_titles(book_soup)       #final_titles, list of strings\n",
    "    star_ratings += retrieve_ratings(book_soup)      #ratings, lsit of ints\n",
    "    prices += retrieve_prices(book_soup)             #prices, list of floats\n",
    "    avails += retrieve_availabilities(book_soup)     #avails, list of strings\n",
    "    \n",
    "    next_url = get_next_page(soup)\n",
    "    if next_url:\n",
    "        next_url = '/'.join(url.split('/')[:-1])+'/' + next_url\n",
    "        return parse_url(next_url, final_titles, star_ratings, prices, avails)\n",
    "    else:\n",
    "        return final_titles, star_ratings, prices, avails\n",
    "\n",
    "url = 'http://books.toscrape.com/'\n",
    "final_titles, star_ratings, prices, avails = parse_url(url, final_titles, star_ratings, prices, avails)\n",
    "        \n",
    "book_frame = pd.DataFrame([final_titles, star_ratings, prices, avails]).transpose()\n",
    "book_frame.columns = ['Title', 'Star_Rating', 'Price_(pounds)', 'Availability']\n",
    "book_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! You just completed your first full web scraping project! You're ready to start harnessing the power of the web!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
